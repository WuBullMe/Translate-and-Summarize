{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b699c812-ae47-4b06-975f-629a74f04c53",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45766396-1ded-462e-99d3-c4675ce23696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "import datasets\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70de2ae-6edf-4d29-a7ec-374c1821075f",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de5df749-9b20-4f19-9842-ce4268d9bdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748efb10faf44ab2a4082f103e0df48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee718d3e27a04487a70f865b7511acb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/10.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d36209ce7d44a9fa6032c1c0e0cb7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70bd1beadd734e7388241d75d8e7897f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/57.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e876668863a48c18bcb05d015cfd46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/572717 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"opus_wikipedia\", \"en-ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1c1bb-c283-43f0-9b82-436d126f43b0",
   "metadata": {},
   "source": [
    "# Download model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ad04dc7-41c6-478f-a236-35e32fdb786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"Mprimus/T5-translation\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(checkpoint)\n",
    "model = T5ForConditionalGeneration.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32bd948e-e05e-492e-b2a2-07cb8d077167",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"translate en-ru: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc[\"en\"] for doc in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=True)\n",
    "    \n",
    "    lebel_inputs = [doc[\"ru\"] for doc in examples[\"translation\"]]\n",
    "    labels = tokenizer(lebel_inputs, max_length=128, truncation=True, padding=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2978de8-7ed8-459d-a21a-9ed8541a5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data['train'].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5c46af5-a40b-41be-800a-f0e33d3288ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fd21ea0517443e9e4dc5e135dede65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/458173 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f89fc6a6f744583a5cce74ed61cdffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/114544 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_data = train_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c532ef2e-0d23-4c27-a5d4-fccae0faf462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 458173\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 114544\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62d790e4-9396-4141-acfc-5f919c7e3ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04c25cb4a9342ae807b229d980abb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True, use_aggregator=True)\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    \n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac6da659-363d-43e4-96bc-1f2fc1cdc0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6b06942e3748f9ac0d75cfb0dc5458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login to push result in huggingface\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4c7b3d-186e-4ea3-98f5-93600033ffd7",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e04800f-0dc2-4bc8-8563-c48046257677",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21de2d15-437a-442e-98c9-37730b7e3545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14318' max='14318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14318/14318 4:04:24, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>0.333595</td>\n",
       "      <td>46.435900</td>\n",
       "      <td>28.750000</td>\n",
       "      <td>45.946200</td>\n",
       "      <td>45.947700</td>\n",
       "      <td>16.983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.331446</td>\n",
       "      <td>46.522300</td>\n",
       "      <td>28.848300</td>\n",
       "      <td>46.031100</td>\n",
       "      <td>46.034700</td>\n",
       "      <td>16.997700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=14318, training_loss=0.40573415744236385, metrics={'train_runtime': 14665.6355, 'train_samples_per_second': 62.483, 'train_steps_per_second': 0.976, 'total_flos': 1.5571851768889344e+17, 'train_loss': 0.40573415744236385, 'epoch': 2.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"T5-translation\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data[\"train\"],\n",
    "    eval_dataset=tokenized_train_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d712083-bece-465a-ac86-74363b76fdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951a89deaf6c4d61bd26a74d02e6721a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/977M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/Mprimus/T5-translation/tree/main/'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push model to huggingface\n",
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d35f90-a87c-46e2-959c-a7413c591071",
   "metadata": {},
   "source": [
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af94256e-dea8-469f-91fc-fb7e1cc4a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"Mprimus/T5-translation\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "prefix = \"translate en-ru: \"\n",
    "\n",
    "def translate(text, max_length=128):\n",
    "    text = prefix + text\n",
    "    model_inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(model_inputs, num_beams=2, max_new_tokens=max_length)\n",
    "    \n",
    "    res = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    \n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "08fbc1eb-556f-45b4-9d29-e85809c04ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Звезда Гарри Поттера Дэниел Рэдклифф получает доступ к £20 млн ($41,1 млн) богатству, когда он становится 18 лет.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Harry Potter star Daniel Radcliffe gains access to a reported £20 million ($41.1 million) fortune as he turns 18 on Monday, but he insists the money won't cast a spell on him.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
